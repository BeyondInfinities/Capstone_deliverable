@article{cite1,
  author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  title = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  doi = {10.48550/arXiv.1810.04805},
  url = {https://arxiv.org/abs/1810.04805},
  urldate = {2023-02-24},
  year = {2018},
  journal = {arXiv.org}
}

@article{cite2,
  author = {Xia, Patrick and Wu, Shijie and Durme, Van},
  title = {Which *BERT? A Survey Organizing Contextualized Encoders},
  doi = {10.48550/arXiv.2010.00854},
  url = {https://arxiv.org/abs/2010.00854},
  urldate = {2023-02-24},
  year = {2020},
  journal = {arXiv.org}
}

@misc{cite3, title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding}, url={https://www.semanticscholar.org/paper/BERT%3A-Pre-training-of-Deep-Bidirectional-for-Devlin-Chang/df2b0e26d0599ce3e70df8a9da02e51594e0e992}, journal={ArXiv}, publisher={ }, author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina}, year={2019} }

@article{cite4, title={More Bang for Your Buck: Natural Perturbation for Robust Question Answering}, url={https://arxiv.org/abs/2004.04849}, DOI={https://doi.org/10.48550/arXiv.2004.04849}, journal={arXiv.org}, author={Khashabi, Daniel and Khot, Tushar and Sabharwal, Ashish}, year={2020} }
@article{cite5, title={Fine-tune the Entire RAG Architecture (including DPR retriever) for Question-Answering}, url={https://arxiv.org/abs/2106.11517}, DOI={https://doi.org/10.48550/arXiv.2106.11517}, journal={arXiv.org}, author={Siriwardhana, Shamane and Weerasekera, Rivindu and Wen, Elliott and Nanayakkara, Suranga}, year={2021} }
@article{cite6, title={Exploiting Cloze Questions for Few Shot Text Classification and Natural Language Inference}, url={https://arxiv.org/abs/2001.07676}, DOI={https://doi.org/10.48550/arXiv.2001.07676}, journal={arXiv.org}, author={Schick, Timo and Schütze, Hinrich}, year={2020} }

@article{cite7, title={What Are People Asking About COVID-19? A Question Classification Dataset}, url={https://arxiv.org/abs/2005.12522}, DOI={https://doi.org/10.48550/arXiv.2005.12522}, journal={arXiv.org}, author={Wei, Jerry and Huang, Chengyu and Vosoughi, Soroush and Wei, Jason}, year={2020} }
@article{cite8, title={BERT for Joint Intent Classification and Slot Filling}, url={https://arxiv.org/abs/1902.10909}, DOI={https://doi.org/10.48550/arXiv.1902.10909}, journal={arXiv.org}, author={Chen, Qian and Zhuo, Zhu and Wang, Wen}, year={2019} }
@article{cite9, title={Few-shot Intent Classification and Slot Filling with Retrieved Examples}, url={https://arxiv.org/abs/2104.05763}, DOI={https://doi.org/10.48550/arXiv.2104.05763}, journal={arXiv.org}, author={Yu, Dian and He, Luheng and Zhang, Yuan and Du, Xinya and Pasupat, Panupong and Li, Qi}, year={2021} }
‌@article{cite10, title={Pretrained Language Models for Text Generation: A Survey}, url={https://arxiv.org/abs/2105.10311}, DOI={https://doi.org/10.48550/arXiv.2105.10311}, journal={arXiv.org}, author={Li, Junyi and Tang, Tianyi and Zhao, Wayne Xin and Wen, Ji-Rong}, year={2021} }
@article{cite11, title={Pretrained Language Models for Text Generation: A Survey}, url={https://arxiv.org/abs/2201.05273}, DOI={https://doi.org/10.48550/arXiv.2201.05273}, journal={arXiv.org}, author={Li, Junyi and Tang, Tianyi and Zhao, Wayne Xin and Nie, Jian-Yun and Wen, Ji-Rong}, year={2022} }
‌@article{cite12, title={A Review of Recent Work in Transfer Learning and Domain Adaptation for Natural Language Processing of Electronic Health Records}, volume={30}, url={https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8416218/}, DOI={https://doi.org/10.1055/s-0041-1726522}, number={01}, journal={Yearbook of Medical Informatics}, author={Laparra, Egoitz and Mascio, Aurelie and Velupillai, Sumithra and Miller, Timothy}, year={2021}, month={Aug}, pages={239–244} }
@article{cite13, title={Gender Bias in BERT - Measuring and Analysing Biases through Sentiment Rating in a Realistic Downstream Classification Task}, url={https://aclanthology.org/2022.gebnlp-1.20/}, DOI={https://doi.org/10.18653/v1/2022.gebnlp-1.20}, journal={Proceedings of the 4th Workshop on Gender Bias in Natural Language Processing (GeBNLP)}, author={Jentzsch, Sophie and Turan, Cigdem}, year={2022} }
@article{cite14, title={Aligning Books and Movies: Towards Story-Like Visual Explanations by Watching Movies and Reading Books}, url={https://openaccess.thecvf.com/content_iccv_2015/html/Zhu_Aligning_Books_and_ICCV_2015_paper.html}, journal={Thecvf.com}, author={Zhu, Yukun and Kiros, Ryan and Zemel, Rich and Salakhutdinov, Ruslan and Urtasun, Raquel and Torralba, Antonio and Fidler, Sanja}, year={2015}, pages={19–27} }

@article{cite15, title={Psychological biases and heuristics in the context of foresight and scenario processes}, volume={2}, url={https://onlinelibrary.wiley.com/doi/full/10.1002/ffo2.31#:~:text=1.1%20Heuristics%20and%20biases%20in%20psychological%20research&text=Biases%20are%20in%20substantial%20parts,Zimmer%20%26%20Fahrenberg%2C%202014).}, DOI={https://doi.org/10.1002/ffo2.31}, number={2}, journal={FUTURES & FORESIGHT SCIENCE}, author={Schirrmeister, Elna and Göhring, Anne‐Louise and Warnke, Philine}, year={2020}, month={Feb} }
@article{cite15.1 al._2017, title={Lack of Associations between Female Hormone Levels and Visuospatial Working Memory, Divided Attention and Cognitive Bias across Two Consecutive Menstrual Cycles}, volume={11}, url={https://www.frontiersin.org/articles/10.3389/fnbeh.2017.00120/full}, DOI={https://doi.org/10.3389/fnbeh.2017.00120}, journal={Frontiers in Behavioral Neuroscience}, author={Leeners, Brigitte and Kruger, Tillmann H. C. and Geraedts, Kirsten and Tronci, Enrico and Mancini, Toni and Ille, Fabian and Egli, Marcel and Röblitz, Susanna and Saleh, Lanja and Spanaus, Katharina and Schippert, Cordula and Zhang, Yuangyuang and Hengartner, Michael P.}, year={2017}, month={Jul} }
@article{cite16, title={Gene × environment interaction on intergroup bias: the role of5-HTTLPRand perceived outgroup threat}, volume={9}, url={https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4158363/}, DOI={https://doi.org/10.1093/scan/nst111}, number={9}, journal={Social Cognitive and Affective Neuroscience}, author={Cheon, Bobby K. and Livingston, Robert W. and Hong, Ying-Yi and Chiao, Joan Y.}, year={2013}, month={Aug}, pages={1268–1275} }

@misc{cite17, url={https://psycnet.apa.org/doiLanding?doi=10.1037%2F0022-3514.70.6.1142}, journal={Apa.org}, year={2023} }

‌
@article{cite18, title={Twenty Years of Stereotype Threat Research: A Review of Psychological Mediators}, volume={11}, url={https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4713435/}, DOI={https://doi.org/10.1371/journal.pone.0146487}, number={1}, journal={PLOS ONE}, author={Pennington, Charlotte R. and Heim, Derek and Levy, Andrew R. and Larkin, Derek T.}, editor={Pavlova, Marina A.}, year={2016}, month={Jan}, pages={e0146487} }
@article{cite19, title={Race and Ethnic Stereotypes in the Media}, ISBN={9780190228613}, url={https://oxfordre.com/communication/display/10.1093/acrefore/9780190228613.001.0001/acrefore-9780190228613-e-1262;jsessionid=794DF3CF7ACE6E29C11FA2F36DD60804}, DOI={https://doi.org/10.1093/acrefore/9780190228613.013.1262}, journal={Oxford Research Encyclopedia of Communication}, author={Ramasubramanian, Srividya and Riewestahl, Emily and Ramirez, Anthony}, year={2023}, month={Jan} }
@article{cite20, title={Perception and misperception of bias in human judgment}, volume={11}, url={https://pubmed.ncbi.nlm.nih.gov/17129749/}, DOI={https://doi.org/10.1016/j.tics.2006.11.001}, number={1}, journal={Trends in Cognitive Sciences}, author={Pronin, Emily}, year={2007}, month={Jan}, pages={37–43} }
@misc{cite21, url={https://www.statista.com/statistics/266808/the-most-spoken-languages-worldwide/}, author={Statista}, publisher={Statista}, year={2022} }
@misc{cite22, title={Discovering English dialects (2008 edition) | Open Library}, url={https://openlibrary.org/books/OL23740927M/Discovering_English_dialects}, journal={Open Library}, author={OpenLibrary.org}, year={2019} }
@article{cite23, title={3. The relationship between African American Vernacular English and White Vernaculars in the American South}, url={https://benjamins.com/catalog/veaw.g27.08bai}, DOI={https://doi.org/10.1075/veaw.g27.08bai}, journal={Varieties of English Around the World}, author={Bailey, Guy}, year={2001}, pages={53} }
@article{cite24, title={Language that dare not speak its name}, volume={386}, url={https://www.nature.com/articles/386321a0}, DOI={https://doi.org/10.1038/386321a0}, number={6623}, journal={Nature}, author={Pullum, Geoffrey K.}, year={1997}, month={Mar}, pages={321–322} }
@article{cite25, title={Language ideologies and the education of speakers of marginalized language varieties: Adopting a critical awareness approach}, volume={17}, url={https://www.sciencedirect.com/science/article/abs/pii/S0898589806000817}, DOI={https://doi.org/10.1016/j.linged.2006.08.002}, number={2}, journal={Linguistics and Education}, author={Siegel, Jeff}, year={2006}, month={Jun}, pages={157–174} }
@article{cite26, title={Investigating African-American Vernacular English in Transformer-Based Text Generation}, url={https://aclanthology.org/2020.emnlp-main.473/}, DOI={https://doi.org/10.18653/v1/2020.emnlp-main.473}, journal={Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)}, author={Groenwold, Sophie and Ou, Lily and Parekh, Aesha and Honnavalli, Samhita and Levy, Sharon and Mirza, Diba and Wang, William Yang}, year={2020} }
@article{cite27, title={The significance of cows in Indian society between sacredness and economy}, volume={18}, url={http://www.drustvo-antropologov.si/AN/PDF/2012_3/Anthropological_Notebooks_XVIII_3_Agoramoorthy.pdf}, number={3}, journal={ANTHROPOLOGICAL NOTEBOOKS}, author={Agoramoorthy, Govindasamy and Hsu, Minna}, pages={5–12} }

‌@inproceedings{cite28,
	author = {Gururangan, Suchin and Swayamdipta, Swabha and Levy, Omer and Schwartz, Roy and Bowman, Samuel and Smith, Noah A.},
	booktitle = {Proceedings of the 2018 {Conference} of the {North} {American} {Chapter} of
          the {Association} for {Computational} {Linguistics}: Human {Language}
          {Technologies}, {Volume} 2 ({Short} {Papers})},
	year = {2018},
	organization = {Association for Computational Linguistics},
	title = {Annotation {Artifacts} in {Natural} {Language} {Inference} {Data}},
	url = {http://dx.doi.org/10.18653/v1/N18-2017},
	doi = {10.18653/v1/n18-2017},
	abstract = {Large-scale datasets for natural language inference are created by presenting crowd workers with a sentence (premise), and asking them to generate three new sentences (hypotheses) that it entails, contradicts, or is logically neutral with respect to. We show that, in a significant portion of such data, this protocol leaves clues that make it possible to identify the label by looking only at the hypothesis, without observing the premise. Specifically, we show that a simple text categorization model can correctly classify the hypothesis alone in about 67% of SNLI (Bowman et. al, 2015) and 53% of MultiNLI (Williams et. al, 2017). Our analysis reveals that specific linguistic phenomena such as negation and vagueness are highly correlated with certain inference classes. Our findings suggest that the success of natural language inference models to date has been overestimated, and that the task remains a hard open problem.},
}


@inproceedings{cite29,
	author = {Shah, Deven Santosh and Schwartz, H. Andrew and Hovy, Dirk},
	booktitle = {Proceedings of the 58th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}},
	year = {2020},
	organization = {Association for Computational Linguistics},
	title = {Predictive {Biases} in {Natural} {Language} {Processing} {Models}: A {Conceptual} {Framework} and {Overview}},
	url = {http://dx.doi.org/10.18653/v1/2020.acl-main.468},
	doi = {10.18653/v1/2020.acl-main.468},
	abstract = {An increasing number of natural language processing papers address the effect of bias on predictions, introducing mitigation techniques at different parts of the standard NLP pipeline (data and models). However, these works have been conducted individually, without a unifying framework to organize efforts within the field. This situation leads to repetitive approaches, and focuses overly on bias symptoms/effects, rather than on their origins, which could limit the development of effective countermeasures. In this paper, we propose a unifying predictive bias framework for NLP. We summarize the NLP literature and suggest general mathematical definitions of predictive bias. We differentiate two consequences of bias: outcome disparities and error disparities, as well as four potential origins of biases: label bias, selection bias, model overamplification, and semantic bias. Our framework serves as an overview of predictive bias in NLP, integrating existing work into a single structure, and providing a conceptual baseline for improved frameworks.},
}


@article{cite30,
	author = {Dayanik, Erenay and Vu, Ngoc Thang and Pad{\' o}, Sebastian},
	journal = {Northern European Journal of Language Technology},
	number = {1},
	year = {2022},
	month = {aug 11},
	publisher = {Linkoping University Electronic Press},
	title = {Analysis of {Bias} in {NLP} {Models} {With} {Regression} and {Effect} {Sizes}},
	volume = {8},
	url = {http://dx.doi.org/10.3384/nejlt.2000-1533.2022.3505},
	doi = {10.3384/nejlt.2000-1533.2022.3505},
	abstract = {In recent years, there has been an increasing awareness that many NLP systems incorporate biases of various types (e.g., regarding gender or race) which can have significant negative consequences. At the same time, the techniques used to statistically analyze such biases are still relatively simple. Typically, studies test for the presence of a significant difference between two levels of a single bias variable (e.g., male vs. female) without attention to potential confounders, and do not quantify the importance of the bias variable. This article proposes to analyze bias in the output of NLP systems using multivariate regression models. They provide a robust and more informative alternative which (a) generalizes to multiple bias variables, (b) can take covariates into account, (c) can be combined with measures of effect size to quantify the size of bias. Jointly, these effects contribute to a more robust statistical analysis of bias that can be used to diagnose system behavior and extract informative examples. We demonstrate the benefits of our method by analyzing a range of current NLP models on one regression and one classification tasks (emotion intensity prediction and coreference resolution, respectively).},
}
@misc{cite31,
	author = {{Felipe Almeida} and {Geraldo Xexéo}},
	title = {Word {Embeddings}: A {Survey}},
	abstract = {This work lists and describes the main recent strategies for building fixed-length, dense and distributed representations for words, based on the distributional hypothesis. These representations are now commonly called word embeddings and, in addition to encoding surprisingly good syntactic and semantic information, have been proven useful as extra features in many downstream NLP tasks.},
}


